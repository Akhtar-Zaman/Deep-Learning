{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM-ECG.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ZKPJ7BLOZVUvmorCEp4zkkq4xPUneQ7C","authorship_tag":"ABX9TyO2RqnaB4nedPWF3UYZOIHo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RGj3ZXZSRduV","executionInfo":{"status":"ok","timestamp":1602229007402,"user_tz":-360,"elapsed":4125,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["from numpy import array\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM\n","from keras.layers import GlobalMaxPooling1D\n","from keras.models import Model\n","from keras.layers.embeddings import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","from keras.layers.merge import Concatenate\n","from keras.layers import Bidirectional\n","\n","\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.utils import np_utils\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","import pandas as pd\n","import numpy as np\n","import re\n","\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"_E9AsHDgR0fG","executionInfo":{"status":"ok","timestamp":1602229013835,"user_tz":-360,"elapsed":10543,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["dataset = pd.read_csv(r'/content/drive/My Drive/Deep Learning/ECG/ECG-Dataset/ECG.csv')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"UI9NEn7Z9RLi","executionInfo":{"status":"ok","timestamp":1602229013837,"user_tz":-360,"elapsed":10530,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"68597dc1-37af-4c17-9c5a-9fd0059dcdcd","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset_500_signal = dataset[0:62500]\n","print(len(dataset_500_signal))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["62500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P8H_5MLa-o8G","executionInfo":{"status":"ok","timestamp":1602229013839,"user_tz":-360,"elapsed":10512,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"3cbde6e5-ad06-4cf6-885d-ef287f55d537","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset_500_signal.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62500, 3)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"2epL1QRoTpJP","executionInfo":{"status":"ok","timestamp":1602229013840,"user_tz":-360,"elapsed":10506,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["X = dataset_500_signal.iloc[:, 1:-1]\n","Y = dataset_500_signal.iloc[:, -1]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"2L0xnK2LS8EX","executionInfo":{"status":"ok","timestamp":1602229013841,"user_tz":-360,"elapsed":10489,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"2229a368-e1e4-4647-9897-ace146f280c2","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# print(\"X= \", X.head())\n","# print(\"Y= \", Y.head())\n","print(\"X shape: \", X.shape)\n","print(\"Y shape: \", Y.shape)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["X shape:  (62500, 1)\n","Y shape:  (62500,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FqTpplzYQNX_","executionInfo":{"status":"ok","timestamp":1602229013842,"user_tz":-360,"elapsed":10480,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","sc_X = MinMaxScaler()\n","sc_y = MinMaxScaler()\n","X = sc_X.fit_transform(X)\n","Y = sc_y.fit_transform(np.array(Y).reshape(-1,1))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKnPgBMjSTYN","executionInfo":{"status":"ok","timestamp":1602229013843,"user_tz":-360,"elapsed":10474,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["X =np.array(X).reshape(62500, 1, 1)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7KQB1-aTG-y","executionInfo":{"status":"ok","timestamp":1602229013844,"user_tz":-360,"elapsed":10468,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZmfsY5ay8at","executionInfo":{"status":"ok","timestamp":1602229019113,"user_tz":-360,"elapsed":15719,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"150763af-fcac-4c53-aa8c-ca46f3d7df74","colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["  # create model\n","model = Sequential()\n","model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(1, 1)))\n","model.add(LSTM(110, activation='relu', return_sequences=True))\n","model.add(LSTM(50, activation='relu'))\n","model.add(Dense(4, activation='softmax'))\n","\t# Compile model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 1, 128)            66560     \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 1, 110)            105160    \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 50)                32200     \n","_________________________________________________________________\n","dense (Dense)                (None, 4)                 204       \n","=================================================================\n","Total params: 204,124\n","Trainable params: 204,124\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T3d8MpxkzKTv","executionInfo":{"status":"ok","timestamp":1602233197640,"user_tz":-360,"elapsed":4194232,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"c8cb2d83-107a-4b00-ddff-347128d8aafb","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(X_train, y_train, epochs=100, batch_size=5)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","10000/10000 [==============================] - 39s 4ms/step - loss: 0.5310 - accuracy: 0.5200\n","Epoch 2/100\n","10000/10000 [==============================] - 39s 4ms/step - loss: 0.4748 - accuracy: 0.5725\n","Epoch 3/100\n","10000/10000 [==============================] - 39s 4ms/step - loss: 0.4722 - accuracy: 0.5743\n","Epoch 4/100\n","10000/10000 [==============================] - 39s 4ms/step - loss: 0.4715 - accuracy: 0.5732\n","Epoch 5/100\n","10000/10000 [==============================] - 39s 4ms/step - loss: 0.4702 - accuracy: 0.5735\n","Epoch 6/100\n","10000/10000 [==============================] - 39s 4ms/step - loss: 0.4659 - accuracy: 0.5742\n","Epoch 7/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4637 - accuracy: 0.5741\n","Epoch 8/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4645 - accuracy: 0.5734\n","Epoch 9/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4628 - accuracy: 0.5749\n","Epoch 10/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4627 - accuracy: 0.5752\n","Epoch 11/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4626 - accuracy: 0.5737\n","Epoch 12/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4618 - accuracy: 0.5743\n","Epoch 13/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4618 - accuracy: 0.5753\n","Epoch 14/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4613 - accuracy: 0.5747\n","Epoch 15/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4615 - accuracy: 0.5746\n","Epoch 16/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4608 - accuracy: 0.5746\n","Epoch 17/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4605 - accuracy: 0.5754\n","Epoch 18/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4607 - accuracy: 0.5740\n","Epoch 19/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4604 - accuracy: 0.5740\n","Epoch 20/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4601 - accuracy: 0.5745\n","Epoch 21/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4599 - accuracy: 0.5751\n","Epoch 22/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4592 - accuracy: 0.5741\n","Epoch 23/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4598 - accuracy: 0.5744\n","Epoch 24/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4595 - accuracy: 0.5742\n","Epoch 25/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4596 - accuracy: 0.5743\n","Epoch 26/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4591 - accuracy: 0.5742\n","Epoch 27/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4591 - accuracy: 0.5751\n","Epoch 28/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4592 - accuracy: 0.5748\n","Epoch 29/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4587 - accuracy: 0.5744\n","Epoch 30/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4588 - accuracy: 0.5746\n","Epoch 31/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4590 - accuracy: 0.5740\n","Epoch 32/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4584 - accuracy: 0.5737\n","Epoch 33/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4581 - accuracy: 0.5751\n","Epoch 34/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4586 - accuracy: 0.5746\n","Epoch 35/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4584 - accuracy: 0.5744\n","Epoch 36/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4580 - accuracy: 0.5744\n","Epoch 37/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4583 - accuracy: 0.5753\n","Epoch 38/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4582 - accuracy: 0.5743\n","Epoch 39/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4584 - accuracy: 0.5750\n","Epoch 40/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4582 - accuracy: 0.5748\n","Epoch 41/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4581 - accuracy: 0.5746\n","Epoch 42/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4580 - accuracy: 0.5748\n","Epoch 43/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4580 - accuracy: 0.5743\n","Epoch 44/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4580 - accuracy: 0.5742\n","Epoch 45/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4580 - accuracy: 0.5746\n","Epoch 46/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4579 - accuracy: 0.5749\n","Epoch 47/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4580 - accuracy: 0.5750\n","Epoch 48/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4579 - accuracy: 0.5749\n","Epoch 49/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4576 - accuracy: 0.5750\n","Epoch 50/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4577 - accuracy: 0.5742\n","Epoch 51/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4577 - accuracy: 0.5746\n","Epoch 52/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4575 - accuracy: 0.5750\n","Epoch 53/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4578 - accuracy: 0.5750\n","Epoch 54/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4576 - accuracy: 0.5744\n","Epoch 55/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4576 - accuracy: 0.5743\n","Epoch 56/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4574 - accuracy: 0.5746\n","Epoch 57/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4576 - accuracy: 0.5749\n","Epoch 58/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4578 - accuracy: 0.5744\n","Epoch 59/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4575 - accuracy: 0.5749\n","Epoch 60/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4576 - accuracy: 0.5750\n","Epoch 61/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4578 - accuracy: 0.5750\n","Epoch 62/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4576 - accuracy: 0.5746\n","Epoch 63/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4574 - accuracy: 0.5738\n","Epoch 64/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4577 - accuracy: 0.5745\n","Epoch 65/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4574 - accuracy: 0.5749\n","Epoch 66/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4574 - accuracy: 0.5743\n","Epoch 67/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4571 - accuracy: 0.5752\n","Epoch 68/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4574 - accuracy: 0.5751\n","Epoch 69/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4574 - accuracy: 0.5749\n","Epoch 70/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4574 - accuracy: 0.5744\n","Epoch 71/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4574 - accuracy: 0.5746\n","Epoch 72/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4570 - accuracy: 0.5747\n","Epoch 73/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4568 - accuracy: 0.5747\n","Epoch 74/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4573 - accuracy: 0.5739\n","Epoch 75/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4571 - accuracy: 0.5749\n","Epoch 76/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4575 - accuracy: 0.5748\n","Epoch 77/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4571 - accuracy: 0.5745\n","Epoch 78/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4570 - accuracy: 0.5747\n","Epoch 79/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4569 - accuracy: 0.5754\n","Epoch 80/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4571 - accuracy: 0.5749\n","Epoch 81/100\n","10000/10000 [==============================] - 43s 4ms/step - loss: 0.4571 - accuracy: 0.5747\n","Epoch 82/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4572 - accuracy: 0.5749\n","Epoch 83/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4569 - accuracy: 0.5751\n","Epoch 84/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4570 - accuracy: 0.5749\n","Epoch 85/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4573 - accuracy: 0.5751\n","Epoch 86/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4574 - accuracy: 0.5747\n","Epoch 87/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4571 - accuracy: 0.5744\n","Epoch 88/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4568 - accuracy: 0.5749\n","Epoch 89/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4568 - accuracy: 0.5748\n","Epoch 90/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4569 - accuracy: 0.5751\n","Epoch 91/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4568 - accuracy: 0.5749\n","Epoch 92/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4568 - accuracy: 0.5745\n","Epoch 93/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4568 - accuracy: 0.5744\n","Epoch 94/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4568 - accuracy: 0.5744\n","Epoch 95/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4568 - accuracy: 0.5753\n","Epoch 96/100\n","10000/10000 [==============================] - 42s 4ms/step - loss: 0.4569 - accuracy: 0.5749\n","Epoch 97/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4567 - accuracy: 0.5743\n","Epoch 98/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4570 - accuracy: 0.5745\n","Epoch 99/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4571 - accuracy: 0.5745\n","Epoch 100/100\n","10000/10000 [==============================] - 41s 4ms/step - loss: 0.4567 - accuracy: 0.5748\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fdbf207bc50>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"w24dxprwzPt8","executionInfo":{"status":"ok","timestamp":1602233198990,"user_tz":-360,"elapsed":4195567,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"b0521b4d-d2e7-458a-9bee-b8c2656a8b92","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Accuracy: 58.06%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_4pBbdvKzcPn"},"source":["# **Cross Vlaidation**"]},{"cell_type":"code","metadata":{"id":"P1YnWbuozlDX","executionInfo":{"status":"ok","timestamp":1602233200003,"user_tz":-360,"elapsed":4196566,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["dataset = pd.read_csv(r'/content/drive/My Drive/Deep Learning/ECG/ECG-Dataset/ECG.csv')\n","dataset_500_signal = dataset[0:62500]\n","\n","X = dataset_500_signal.iloc[:, 1:-1]\n","Y = dataset_500_signal.iloc[:, -1]\n","\n","from sklearn.preprocessing import MinMaxScaler\n","sc_X = MinMaxScaler()\n","sc_y = MinMaxScaler()\n","X = sc_X.fit_transform(X)\n","Y = sc_y.fit_transform(np.array(Y).reshape(-1,1))\n","\n","X =np.array(X).reshape(62500, 1, 1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMs1m9tAR0vc","executionInfo":{"status":"ok","timestamp":1602233200004,"user_tz":-360,"elapsed":4196556,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["\n","# define baseline model\n","def baseline_model():\n","\t# create model\n","  model = Sequential()\n","  model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(1, 1)))\n","  model.add(LSTM(110, activation='relu', return_sequences=True))\n","  model.add(LSTM(50, activation='relu'))\n","  model.add(Dense(4, activation='softmax'))\n","  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGEMDnFnY0OP","outputId":"ddfd2eed-5c04-4f9e-8e7e-8bdb50d0e3eb","colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["estimator = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n","kfold = KFold(n_splits=5, shuffle=True)\n","results = cross_val_score(estimator, X, Y, cv=kfold)\n","print(\"Accuracy: %.2f%%\" % (results.mean()*100))\n","print(\"Starndard daviation: %.2f%%\" % (results.std()*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stdout"}]}]}