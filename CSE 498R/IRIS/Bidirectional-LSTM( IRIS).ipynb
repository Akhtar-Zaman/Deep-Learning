{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bidirectional-LSTM( IRIS).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1e8bGEzwIISnmomjhODHcdKyVH2U7quj0","authorship_tag":"ABX9TyOvjFSP6X/0HyQo7XyYpoWA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WzxPfgcDMWfN","executionInfo":{"status":"ok","timestamp":1601484444065,"user_tz":-360,"elapsed":1203,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM\n","from keras.layers import GlobalMaxPooling1D\n","from keras.models import Model\n","from keras.layers.embeddings import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","from keras.layers.merge import Concatenate\n","from keras.layers import Bidirectional\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.utils.vis_utils import plot_model\n","\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjdRNWGIMzAx","executionInfo":{"status":"ok","timestamp":1601484450308,"user_tz":-360,"elapsed":1110,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["dataset = pd.read_csv(r'/content/drive/My Drive/Deep Learning/IRIS/Dataset/Iris1.csv')\n","\n","X = dataset.iloc[:, :-1]\n","Y = dataset.iloc[:, -1]\n","X = X.values.reshape(150, 1, 1)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"cGaw30D91naU","executionInfo":{"status":"ok","timestamp":1601484455238,"user_tz":-360,"elapsed":2127,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"U6H62qchuAv9","executionInfo":{"status":"ok","timestamp":1601484457263,"user_tz":-360,"elapsed":1104,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"6617ecc0-ce2e-45cd-c54f-15e6d60353e4","colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["  # create model\n","model = Sequential()\n","model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(1, 1)))\n","model.add(Dense(3, activation='softmax'))\n","\t# Compile model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","  #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_10 (Bidirectio (None, 100)               20800     \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 3)                 303       \n","=================================================================\n","Total params: 21,103\n","Trainable params: 21,103\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iEbkuSsxuAz_","executionInfo":{"status":"ok","timestamp":1601484476390,"user_tz":-360,"elapsed":13532,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"49198f11-9479-4616-af79-9a375f1efdfa","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(X_train, y_train, epochs=100, batch_size=5)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","24/24 [==============================] - 0s 5ms/step - loss: 1.0989 - accuracy: 0.3250\n","Epoch 2/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0963 - accuracy: 0.3250\n","Epoch 3/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0925 - accuracy: 0.2833\n","Epoch 4/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.3250\n","Epoch 5/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0896 - accuracy: 0.3250\n","Epoch 6/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0874 - accuracy: 0.2500\n","Epoch 7/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0871 - accuracy: 0.3250\n","Epoch 8/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0847 - accuracy: 0.3250\n","Epoch 9/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0841 - accuracy: 0.3250\n","Epoch 10/100\n","24/24 [==============================] - 0s 5ms/step - loss: 1.0814 - accuracy: 0.3250\n","Epoch 11/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0772 - accuracy: 0.3250\n","Epoch 12/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0768 - accuracy: 0.3250\n","Epoch 13/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0747 - accuracy: 0.3917\n","Epoch 14/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0721 - accuracy: 0.3583\n","Epoch 15/100\n","24/24 [==============================] - 0s 5ms/step - loss: 1.0699 - accuracy: 0.2667\n","Epoch 16/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0677 - accuracy: 0.3250\n","Epoch 17/100\n","24/24 [==============================] - 0s 5ms/step - loss: 1.0633 - accuracy: 0.3250\n","Epoch 18/100\n","24/24 [==============================] - 0s 5ms/step - loss: 1.0579 - accuracy: 0.3250\n","Epoch 19/100\n","24/24 [==============================] - 0s 5ms/step - loss: 1.0556 - accuracy: 0.3333\n","Epoch 20/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0551 - accuracy: 0.3750\n","Epoch 21/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0474 - accuracy: 0.4167\n","Epoch 22/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0471 - accuracy: 0.4000\n","Epoch 23/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0429 - accuracy: 0.3500\n","Epoch 24/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0346 - accuracy: 0.5000\n","Epoch 25/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0275 - accuracy: 0.5500\n","Epoch 26/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0239 - accuracy: 0.5667\n","Epoch 27/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0194 - accuracy: 0.4167\n","Epoch 28/100\n","24/24 [==============================] - 0s 5ms/step - loss: 1.0125 - accuracy: 0.5583\n","Epoch 29/100\n","24/24 [==============================] - 0s 4ms/step - loss: 1.0053 - accuracy: 0.6250\n","Epoch 30/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9970 - accuracy: 0.6167\n","Epoch 31/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9896 - accuracy: 0.6500\n","Epoch 32/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9843 - accuracy: 0.6417\n","Epoch 33/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9763 - accuracy: 0.6417\n","Epoch 34/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.9675 - accuracy: 0.6000\n","Epoch 35/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.9604 - accuracy: 0.6750\n","Epoch 36/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.9510 - accuracy: 0.7083\n","Epoch 37/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.9440 - accuracy: 0.6583\n","Epoch 38/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9333 - accuracy: 0.7250\n","Epoch 39/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9275 - accuracy: 0.7000\n","Epoch 40/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9169 - accuracy: 0.7000\n","Epoch 41/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9080 - accuracy: 0.6833\n","Epoch 42/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.9058 - accuracy: 0.7167\n","Epoch 43/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.6917\n","Epoch 44/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8846 - accuracy: 0.6833\n","Epoch 45/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8741 - accuracy: 0.7250\n","Epoch 46/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8681 - accuracy: 0.7250\n","Epoch 47/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8613 - accuracy: 0.6667\n","Epoch 48/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8519 - accuracy: 0.6833\n","Epoch 49/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8466 - accuracy: 0.6333\n","Epoch 50/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8349 - accuracy: 0.7167\n","Epoch 51/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8303 - accuracy: 0.7167\n","Epoch 52/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.7000\n","Epoch 53/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.8167 - accuracy: 0.6750\n","Epoch 54/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8127 - accuracy: 0.7417\n","Epoch 55/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.8069 - accuracy: 0.6500\n","Epoch 56/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7999 - accuracy: 0.7500\n","Epoch 57/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7910 - accuracy: 0.7083\n","Epoch 58/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.7825 - accuracy: 0.7417\n","Epoch 59/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.7333\n","Epoch 60/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7740 - accuracy: 0.7000\n","Epoch 61/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7753 - accuracy: 0.7000\n","Epoch 62/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7710 - accuracy: 0.6333\n","Epoch 63/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7653 - accuracy: 0.7417\n","Epoch 64/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7560 - accuracy: 0.6750\n","Epoch 65/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.7486 - accuracy: 0.7500\n","Epoch 66/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7493 - accuracy: 0.7250\n","Epoch 67/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7399 - accuracy: 0.7250\n","Epoch 68/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.7083\n","Epoch 69/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7337 - accuracy: 0.7000\n","Epoch 70/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7302 - accuracy: 0.7083\n","Epoch 71/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7243 - accuracy: 0.7250\n","Epoch 72/100\n","24/24 [==============================] - 0s 5ms/step - loss: 0.7172 - accuracy: 0.7083\n","Epoch 73/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7185 - accuracy: 0.7167\n","Epoch 74/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.7167\n","Epoch 75/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7123 - accuracy: 0.7167\n","Epoch 76/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7064 - accuracy: 0.7167\n","Epoch 77/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.7167\n","Epoch 78/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.7250\n","Epoch 79/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.7333\n","Epoch 80/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.7083\n","Epoch 81/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.7167\n","Epoch 82/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.7000\n","Epoch 83/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.6667\n","Epoch 84/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.7250\n","Epoch 85/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.7250\n","Epoch 86/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.7083\n","Epoch 87/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.7333\n","Epoch 88/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7083\n","Epoch 89/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.7333\n","Epoch 90/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7167\n","Epoch 91/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.7083\n","Epoch 92/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.7083\n","Epoch 93/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.7250\n","Epoch 94/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7667\n","Epoch 95/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.7250\n","Epoch 96/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.7583\n","Epoch 97/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.7750\n","Epoch 98/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7167\n","Epoch 99/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.7167\n","Epoch 100/100\n","24/24 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.7583\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f4980427dd8>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"yjPXbAlguA3d","executionInfo":{"status":"ok","timestamp":1601484481096,"user_tz":-360,"elapsed":1303,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"c6ac72e0-77fc-4223-b3b7-52e67a070308","colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f49803b8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Accuracy: 70.00%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nBj_-2aH1spE"},"source":["# **Cross Validation**"]},{"cell_type":"code","metadata":{"id":"o8sbP1Rl2Kcu","executionInfo":{"status":"ok","timestamp":1601484238693,"user_tz":-360,"elapsed":2838,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["dataset = pd.read_csv(r'/content/drive/My Drive/Deep Learning/IRIS/Dataset/Iris1.csv')\n","\n","X = dataset.iloc[:, :-1]\n","Y = dataset.iloc[:, -1]\n","X = X.values.reshape(150, 1, 1)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWmrD_1e2iv8","executionInfo":{"status":"ok","timestamp":1601484295998,"user_tz":-360,"elapsed":1265,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}}},"source":["# define baseline model\n","def baseline_modells():\n","\t# create model\n","  model = Sequential()\n","  model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(1, 1)))\n","  model.add(Dense(1))\n","  model.add(Dense(3, activation='softmax'))\n","  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9Hqecev2i2A","executionInfo":{"status":"ok","timestamp":1601484435195,"user_tz":-360,"elapsed":124990,"user":{"displayName":"Akhtar Zaman Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GioZFQRdUPEk6fLGXd9zaAXqbPBPPY1koe3jIzQTw=s64","userId":"07901748164067783075"}},"outputId":"4be2e613-acef-46c8-9bc6-1b03d8ff20fa","colab":{"base_uri":"https://localhost:8080/","height":683}},"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","\n","estimator = KerasClassifier(build_fn=baseline_modells, epochs=100, batch_size=5, verbose=0)\n","kfold = KFold(n_splits=10, shuffle=True)\n","results = cross_val_score(estimator, X, Y, cv=kfold)\n","print(\"Accuracy: %.2f%%\" % (results.mean()*100))\n","print(\"Starndard daviation: %.2f%%\" % (results.std()*100))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f492f9ce9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f492f613620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f49317b2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f498016d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f49316db7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f4930deb8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Accuracy: 66.67%\n","Starndard daviation: 13.33%\n"],"name":"stdout"}]}]}